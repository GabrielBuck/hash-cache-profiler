# parallel-cdn-log-analyzer ‚ö°

## üåç Contexto: por que esse projeto existe?

Hoje, praticamente tudo o que a gente faz na internet passa por uma **CDN (Content Delivery Network)**: assistir s√©ries na **Netflix**, ver v√≠deos no **YouTube**, jogar online, abrir posts do **Instagram**, carregar p√°ginas de e-commerce como **Amazon** ou **Mercado Livre**, etc.

Essas empresas distribuem c√≥pias dos conte√∫dos em v√°rios servidores espalhados pelo mundo ("edge servers"). Quando um v√≠deo, imagem ou p√°gina come√ßa a ser muito acessado, ele se torna um **hot content** (conte√∫do quente) e precisa ser replicado para mais servidores para evitar:

* sobrecarga em poucos servidores,
* aumento de lat√™ncia (site lento),
* quedas de servi√ßo em hor√°rios de pico.

Como a CDN descobre **quais conte√∫dos est√£o quentes**? Analisando **logs de acesso**.

Esse projeto simula exatamente essa situa√ß√£o: temos arquivos de log gigantes (com milh√µes de requisi√ß√µes HTTP), e precisamos:

1. **contar quantos acessos cada URL recebeu**,
2. fazer isso de forma **r√°pida**, aproveitando v√°rios n√∫cleos de CPU (paralelismo),
3. entender como diferentes estrat√©gias de sincroniza√ß√£o influenciam o desempenho.

Em vez de trabalhar diretamente com logs reais da Cloudflare, Akamai, Netflix Open Connect ou Google, geramos logs sint√©ticos, mas com padr√µes realistas:

* um cen√°rio **distribu√≠do**, em que o tr√°fego √© mais homog√™neo;
* um cen√°rio **concorrente / hotspot**, em que poucas URLs concentram quase todo o tr√°fego, como quando uma s√©rie nova lan√ßa na Netflix ou um v√≠deo viraliza no YouTube.

A partir da√≠, o foco do projeto √© **t√©cnico**: usar C + OpenMP + tabela hash para implementar tr√™s vers√µes de analisador de log (sequencial, paralela com `critical` e paralela com `atomic`) e comparar como cada abordagem se comporta nesses cen√°rios.

---

Analisador **paralelo de logs de CDN** escrito em **C** com **OpenMP**, focado em comparar uma vers√£o **sequencial** com duas vers√µes **paralelas** (usando `critical` e `atomic`) em cen√°rios realistas com **10 milh√µes de requisi√ß√µes**.

Este reposit√≥rio serve como **portf√≥lio de Computa√ß√£o Paralela + Estruturas de Dados**, mostrando:

* modelagem de um problema real (an√°lise de logs de CDN),
* implementa√ß√£o de **tabela hash** em C,
* uso de **OpenMP** para paralelizar um pipeline de processamento de logs,
* an√°lise de **speedup, efici√™ncia e conten√ß√£o** em diferentes padr√µes de acesso.

---

## üß≠ Vis√£o geral r√°pida

* **Entrada:** arquivos de log HTTP simulando o acesso a uma CDN (10M linhas).
* **Sa√≠da:** arquivo CSV `results.csv` no formato `URL,hit_count` com o total de acessos por URL.
* **3 implementa√ß√µes comparadas:**

  * `analyzer_seq.c` ‚Äì vers√£o sequencial (baseline),
  * `analyzer_par_critical.c` ‚Äì paralela com `#pragma omp critical`,
  * `analyzer_par_atomic.c` ‚Äì paralela com `#pragma omp atomic`.
* **Cen√°rios de teste:**

  * `log_distribuido.txt` ‚Äì baixa conten√ß√£o (acessos bem distribu√≠dos),
  * `log_concorrente.txt` ‚Äì alta conten√ß√£o (hotspots).

---

## üìÅ Organiza√ß√£o do reposit√≥rio

Sugest√£o de layout (pode ser adaptado conforme seu uso):

```text
parallel-cdn-log-analyzer/
‚îú‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ Makefile                  # script de compila√ß√£o (gcc + OpenMP)
‚îú‚îÄ‚îÄ .gitignore
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ analyzer_seq.c        # vers√£o sequencial
‚îÇ   ‚îú‚îÄ‚îÄ analyzer_par_critical.c # vers√£o paralela com critical
‚îÇ   ‚îú‚îÄ‚îÄ analyzer_par_atomic.c   # vers√£o paralela com atomic
‚îÇ   ‚îú‚îÄ‚îÄ hash_table.c          # implementa√ß√£o da tabela hash
‚îÇ   ‚îî‚îÄ‚îÄ hash_table.h          # interface da tabela hash
‚îú‚îÄ‚îÄ scripts/
‚îÇ   ‚îî‚îÄ‚îÄ generate_cdn_data.py  # gerador de logs e gabaritos
‚îú‚îÄ‚îÄ report/
‚îÇ   ‚îî‚îÄ‚îÄ relatorio_lab2_cdn.pdf  # relat√≥rio do projeto (opcional)
‚îî‚îÄ‚îÄ examples/
    ‚îî‚îÄ‚îÄ (opcional) arquivos pequenos de exemplo de log/csv
```

> üîí **N√£o versionar**: arquivos de log reais (`log_*.txt` com ~900MB), gabaritos completos (`gabarito_*.csv` com milh√µes de linhas), `cdn_data_logs.zip` e execut√°veis.

Exemplo de `.gitignore` m√≠nimo:

```gitignore
# Bin√°rios
analyzer_seq
analyzer_par_critical
analyzer_par_atomic

# Dados grandes gerados
*.txt
*.csv
*.zip

# Mas permita exemplos pequenos
!examples/*.txt
!examples/*.csv

# Objetos e tempor√°rios
*.o
*.out

# Config de IDEs
.vscode/
.idea/
.DS_Store
```

---

## üéØ Objetivos do projeto

* Simular o tr√°fego de uma **CDN (Content Delivery Network)** com:

  * cat√°logo de URLs (`manifest.txt`),
  * padr√µes de acesso **distribu√≠dos** e **concorrentes (hotspot)**.
* Implementar uma **estrutura de dados eficiente** para contagem de acessos:

  * tabela hash com encadeamento separado, escrita em C puro.
* Comparar desempenho entre tr√™s abordagens:

  * vers√£o **sequencial** (1 thread),
  * vers√£o paralela com **regi√£o cr√≠tica** (`#pragma omp critical`),
  * vers√£o paralela com **opera√ß√µes at√¥micas** (`#pragma omp atomic`).
* Discutir, na pr√°tica:

  * impacto de **conten√ß√£o** em vari√°veis compartilhadas,
  * custo de sincroniza√ß√£o vs. ganho de paralelismo,
  * **speedup** e **efici√™ncia** em fun√ß√£o do n√∫mero de threads e do padr√£o de acesso.

---

## üß± Arquitetura da solu√ß√£o

### 1. Gera√ß√£o de dados (Python)

**Arquivo:** `scripts/generate_cdn_data.py`

Este script gera todo o conjunto de dados sint√©ticos:

* `manifest.txt`
  Lista de todas as URLs dispon√≠veis na CDN (cat√°logo de conte√∫dos).

* `log_distribuido.txt`
  Log de acessos com **distribui√ß√£o uniforme** entre as URLs (baixa conten√ß√£o).

* `log_concorrente.txt`
  Log de acessos com **hotspots** (poucas URLs recebem a maior parte dos acessos).

* `gabarito_distribuido.csv`

* `gabarito_concorrente.csv`

Arquivos CSV com o gabarito de contagem no formato:

```text
URL,hit_count
```

> Esses gabaritos s√£o usados para validar a sa√≠da dos analisadores em C via `diff`.

O script tamb√©m pode compactar tudo em `cdn_data_logs.zip` e remover os arquivos originais.

---

### 2. Estrutura de dados: Tabela Hash

**Arquivos:** `src/hash_table.h`, `src/hash_table.c`

A tabela hash mapeia:

```text
URL -> hit_count
```

Caracter√≠sticas principais:

* **Encadeamento separado** para colis√µes (cada bucket √© uma lista encadeada de `CacheNode`).
* Estrutura do `CacheNode`:

  * `char* url` ‚Äì chave (URL),
  * `long hit_count` ‚Äì contador de acessos,
  * `CacheNode* next` ‚Äì pr√≥ximo n√≥ da lista encadeada.
* Hash de string baseado em `djb2`.

API p√∫blica:

* `HashTable* ht_create(size_t size);`
* `void ht_destroy(HashTable* ht);`
* `void ht_insert(HashTable* ht, const char* url);`
* `CacheNode* ht_get(HashTable* ht, const char* url);`
* `void ht_save_results(HashTable* ht, const char* filename);`

A mesma tabela hash √© reutilizada por todas as vers√µes (sequencial e paralelas), permitindo comparar diretamente o efeito da sincroniza√ß√£o.

---

### 3. Analisadores de log (C + OpenMP)

Fluxo geral de todas as vers√µes:

1. Ler `manifest.txt` e inserir todas as URLs na tabela hash com `hit_count = 0`.
2. Ler todas as linhas do arquivo de log (`log_distribuido.txt` ou `log_concorrente.txt`) em mem√≥ria.
3. Para cada linha de log:

   * extrair a URL a partir do padr√£o HTTP:

     ```text
     127.0.0.1 - - [data] "GET /alguma/url.mp4 HTTP/1.1" 200 1500
     ```

   * buscar essa URL na hash (`ht_get`),

   * incrementar o contador `hit_count` correspondente.
4. Salvar o resultado em `results.csv`.
5. Medir o tempo de processamento com `omp_get_wtime()`.
6. (Opcional) Validar a sa√≠da com `diff` em rela√ß√£o ao gabarito.

#### `analyzer_seq.c` ‚Äì Vers√£o sequencial (baseline)

* Processa o log com **1 thread**.
* Percorre todas as linhas, extrai a URL, busca na hash e incrementa o contador.
* Serve como **baseline** (`T_seq`) para c√°lculo de **speedup** e **efici√™ncia**.

#### `analyzer_par_critical.c` ‚Äì Paralelo com `#pragma omp critical`

* Usa `#pragma omp parallel for` para distribuir as linhas entre m√∫ltiplas threads.
* A atualiza√ß√£o da contagem √© protegida por uma **regi√£o cr√≠tica global**:

```c
#pragma omp parallel for
for (size_t i = 0; i < num; i++) {
    // extrai URL e busca na hash
    CacheNode* node = ht_get(ht, url);
    if (node) {
        #pragma omp critical
        node->hit_count++;
    }
}
```

* Garante corretude, mas pode sofrer com **alta conten√ß√£o** quando muitas threads disputam os mesmos poucos contadores.

#### `analyzer_par_atomic.c` ‚Äì Paralelo com `#pragma omp atomic`

* Tamb√©m usa `#pragma omp parallel for`.
* A diferen√ßa est√° na sincroniza√ß√£o do incremento, feita com opera√ß√£o at√¥mica:

```c
#pragma omp parallel for
for (size_t i = 0; i < num; i++) {
    CacheNode* node = ht_get(ht, url);
    if (node) {
        #pragma omp atomic update
        node->hit_count++;
    }
}
```

---

## üìä Resultados de desempenho (resumo)

Os testes foram feitos com arquivos de log de **10 milh√µes de linhas** em ambiente Linux/WSL.

### üîπ Cen√°rio 1 ‚Äì Log distribu√≠do (baixa conten√ß√£o)

Tempo sequencial usado como baseline:

* `T_seq_distribuido ‚âà 3.82 s`

Compara√ß√£o das vers√µes paralelas em fun√ß√£o do n√∫mero de threads:

| Threads | Vers√£o   | Tempo (s) | Speedup vs seq |
| ------: | -------- | --------: | -------------: |
|       1 | critical |      3.76 |          1.01√ó |
|       1 | atomic   |      2.77 |          1.38√ó |
|       2 | critical |      2.10 |          1.82√ó |
|       2 | atomic   |      1.44 |          2.66√ó |
|       4 | critical |      1.57 |          2.43√ó |
|       4 | atomic   |      0.90 |          4.25√ó |
|       8 | critical |      3.88 |          0.98√ó |
|       8 | atomic   |      0.47 |          8.05√ó |

> Em baixa conten√ß√£o, a vers√£o com `atomic` consegue aproveitar bem o paralelismo, chegando pr√≥ximo de **8√ó de speedup com 8 threads**, enquanto `critical` sofre mais com overhead de sincroniza√ß√£o.

### üîπ Cen√°rio 2 ‚Äì Log concorrente (alta conten√ß√£o / hotspot)

Aqui poucas URLs concentram ~90% dos acessos (hot contents).

| Vers√£o                  | Threads | Tempo (s) | Speedup vs seq |
| ----------------------- | ------: | --------: | -------------: |
| Sequencial              |       1 |      1.21 |          1.00√ó |
| Paralela com `critical` |       8 |      2.98 |          0.40√ó |
| Paralela com `atomic`   |       8 |      0.36 |          3.30√ó |

> Em alta conten√ß√£o, `critical` vira gargalo (todas as threads disputam uma √∫nica regi√£o cr√≠tica), chegando a ficar **mais lenta que a vers√£o sequencial**.
> Com `atomic`, a sincroniza√ß√£o √© mais leve e granular, permitindo um speedup de ~**3.3√ó** mesmo em um cen√°rio com muitos acessos √†s mesmas URLs.

---

## üìà Visualiza√ß√£o ‚Äì Speedup por n√∫mero de threads

Para o cen√°rio distribu√≠do, tamb√©m geramos um gr√°fico de **speedup vs n√∫mero de threads**:

```text
Speedup
 9 |                            x (atomic, N=8)
 8 |                         x
 7 |
 6 |
 5 |                    x
 4 |                 x
 3 |
 2 |           x           x
 1 |      x  x
 0 +-----------------------------------------
      N=1    2           4            8

      ‚Ä¢ linha critical  ~ 1.0, 1.8, 2.4, 1.0
      ‚Ä¢ linha atomic    ~ 1.4, 2.7, 4.3, 8.0
```

Se voc√™ quiser incluir o gr√°fico como imagem no reposit√≥rio, salve o PNG em `docs/speedup_distribuido.png` e adicione:

```markdown
![Gr√°fico de speedup ‚Äì log distribu√≠do](docs/speedup_distribuido.png)
```

---

## üß† Skills demonstradas

* Programa√ß√£o paralela em **C + OpenMP** (`parallel for`, `critical`, `atomic`).
* Implementa√ß√£o de **tabela hash** com encadeamento separado para alto volume de dados.
* Medi√ß√£o e an√°lise de **desempenho**, **speedup**, **efici√™ncia** e **conten√ß√£o**.
* Modelagem de um problema real de **CDN / sistemas distribu√≠dos** em um experimento reprodut√≠vel.
