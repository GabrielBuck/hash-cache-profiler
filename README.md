# parallel-cdn-log-analyzer ‚ö°

Analisador paralelo de logs de CDN escrito em **C** com **OpenMP**, focado em comparar vers√µes sequencial e paralelas (usando `critical` e `atomic`) em cen√°rios com milh√µes de requisi√ß√µes.

O projeto simula o comportamento de uma **CDN (Content Delivery Network)**, processando grandes arquivos de log, contando hits por URL com uma **tabela hash** e medindo o impacto da sincroniza√ß√£o na performance.

---

## üéØ Objetivos do projeto

- Simular o tr√°fego de uma CDN com:
  - muitas URLs diferentes (manifesto de conte√∫do)
  - padr√µes de acesso **distribu√≠dos** e **concorrentes (hotspot)**
- Implementar uma **estrutura de dados eficiente** para contagem de acessos:
  - tabela hash com encadeamento separado
- Comparar desempenho entre tr√™s implementa√ß√µes:
  - vers√£o **sequencial**
  - vers√£o paralela com **regi√£o cr√≠tica** (`#pragma omp critical`)
  - vers√£o paralela com **opera√ß√µes at√¥micas** (`#pragma omp atomic`)
- Discutir:
  - impacto de **conten√ß√£o** em vari√°veis compartilhadas
  - custo de sincroniza√ß√£o
  - ganho real de **speedup** e **efici√™ncia** em fun√ß√£o do tamanho da entrada.

---

## üß± Arquitetura da solu√ß√£o

### 1. Gera√ß√£o de dados (Python)

**Arquivo:** `generate_cdn_data.py`

Esse script cria todo o conjunto de dados sint√©ticos:

- `manifest.txt`  
  Lista de todas as URLs dispon√≠veis na CDN (cat√°logo de conte√∫dos).

- `log_distribuido.txt`  
  Log de acessos com **distribui√ß√£o uniforme** entre as URLs.

- `log_concorrente.txt`  
  Log de acessos com **hotspots** (poucas URLs recebem a maior parte dos acessos).

- `gabarito_distribuido.csv`  
- `gabarito_concorrente.csv`  

Arquivos CSV com o gabarito de contagem no formato:

```text
URL,hit_count
```

Esses gabaritos s√£o usados para validar a sa√≠da dos analisadores em C via `diff`.

> üîé Observa√ß√£o: o script compacta tudo em `cdn_data_logs.zip` e apaga os arquivos originais.  
> Para utilizar, basta rodar o script e depois descompactar:
>
> ```bash
> python3 generate_cdn_data.py
> unzip cdn_data_logs.zip
> ```

---

### 2. Estrutura de dados: Tabela Hash

**Arquivos:**

- `hash_table.h`
- `hash_table.c`

A tabela hash mapeia:

```text
URL -> hit_count
```

Caracter√≠sticas principais:

- **Encadeamento separado** para colis√µes (cada bucket √© uma lista encadeada de `CacheNode`).
- Campos do `CacheNode`:
  - `char* url` ‚Äì chave (URL)
  - `long hit_count` ‚Äì contador de acessos
  - `CacheNode* next` ‚Äì pr√≥ximo n√≥ na lista encadeada

API p√∫blica:

- `HashTable* ht_create(size_t size);`
- `void ht_destroy(HashTable* ht);`
- `void ht_insert(HashTable* ht, const char* url);`
- `CacheNode* ht_get(HashTable* ht, const char* url);`
- `void ht_save_results(HashTable* ht, const char* filename);`

A tabela hash √© compartilhada entre as vers√µes sequencial e paralelas.

---

### 3. Analisadores de log

Todos os analisadores seguem o mesmo fluxo geral:

1. Ler `manifest.txt` e inserir todas as URLs na tabela hash com `hit_count = 0`.
2. Ler todas as linhas do arquivo de log (`log_distribuido.txt` ou `log_concorrente.txt`).
3. Para cada linha de log:
   - extrair a URL do padr√£o HTTP:
     
     ```text
     GET /alguma/url.mp4 HTTP/1.1
     ```
   - buscar essa URL na hash (`ht_get`)
   - incrementar o contador da URL.
4. Salvar o resultado em `results.csv`.
5. Comparar `results.csv` com o gabarito usando `diff`.

#### `analyzer_seq.c` ‚Äì Vers√£o sequencial

- Processa o log com **1 thread**.
- Percorre todas as linhas, extrai a URL, faz a busca na tabela hash e incrementa o contador.
- Usado como **baseline** para c√°lculo de speedup e efici√™ncia.

#### `analyzer_par_critical.c` ‚Äì Vers√£o paralela com `critical`

- Utiliza `#pragma omp parallel for` para dividir as linhas entre m√∫ltiplas threads.
- Cada thread:
  - extrai a URL da linha de log
  - busca na hash
  - incrementa o contador dentro de uma regi√£o cr√≠tica:

```c
#pragma omp critical
node->hit_count++;
```

- Garante corre√ß√£o, mas pode sofrer com **alta conten√ß√£o**, especialmente no cen√°rio concorrente (hotspot).

#### `analyzer_par_atomic.c` ‚Äì Vers√£o paralela com `atomic`

- Tamb√©m usa `#pragma omp parallel for`.
- O incremento √© protegido com uma opera√ß√£o at√¥mica:

```c
#pragma omp atomic update
node->hit_count++;
```

- A sincroniza√ß√£o √© mais granular do que `critical`, permitindo melhor escalabilidade quando muitas URLs diferentes s√£o atualizadas em paralelo.

---

## üõ†Ô∏è Tecnologias utilizadas

- **C** (compilado com `gcc`)
- **OpenMP**
  - `#pragma omp parallel for`
  - `#pragma omp critical`
  - `#pragma omp atomic`
- **Python 3** para gera√ß√£o dos dados sint√©ticos
- Ambiente de desenvolvimento/teste:
  - Linux / WSL2
  - `gcc` com suporte a `-fopenmp`

---

## ‚ñ∂Ô∏è Como executar o projeto

### 1. Pr√©-requisitos

```bash
sudo apt update
sudo apt install -y build-essential python3 unzip
```

### 2. Gerar o conjunto de dados

Na pasta do projeto:

```bash
python3 generate_cdn_data.py
unzip cdn_data_logs.zip
```

Arquivos gerados:

- `manifest.txt`
- `log_distribuido.txt`
- `log_concorrente.txt`
- `gabarito_distribuido.csv`
- `gabarito_concorrente.csv`

### 3. Compilar os analisadores

```bash
gcc -Wall -O2 -fopenmp analyzer_seq.c          hash_table.c -o analyzer_seq
gcc -Wall -O2 -fopenmp analyzer_par_critical.c hash_table.c -o analyzer_par_critical
gcc -Wall -O2 -fopenmp analyzer_par_atomic.c   hash_table.c -o analyzer_par_atomic
```

### 4. Rodar e validar (exemplo)

#### Log distribu√≠do

```bash
# Vers√£o sequencial
./analyzer_seq log_distribuido.txt
tr -d '\r' < results.csv > results_seq_distribuido_unix.csv
tr -d '\r' < gabarito_distribuido.csv > gabarito_distribuido_unix.csv
diff gabarito_distribuido_unix.csv results_seq_distribuido_unix.csv
```

```bash
# Vers√£o paralela com critical (exemplo com 8 threads)
export OMP_NUM_THREADS=8
./analyzer_par_critical log_distribuido.txt
tr -d '\r' < results.csv > results_critical_distribuido_unix.csv
diff gabarito_distribuido_unix.csv results_critical_distribuido_unix.csv
```

```bash
# Vers√£o paralela com atomic (exemplo com 8 threads)
export OMP_NUM_THREADS=8
./analyzer_par_atomic log_distribuido.txt
tr -d '\r' < results.csv > results_atomic_distribuido_unix.csv
diff gabarito_distribuido_unix.csv results_atomic_distribuido_unix.csv
```

#### Log concorrente (hotspot)

Repita o mesmo processo usando `log_concorrente.txt` e `gabarito_concorrente.csv`.

---

## üìä Estrutura sugerida para resultados

> Preencha esta se√ß√£o com os tempos medidos na sua m√°quina.

### Log distribu√≠do

| Vers√£o             | Threads | Tempo (s) | Speedup | Efici√™ncia |
|--------------------|---------|-----------|---------|-----------|
| Sequencial         | 1       |           | 1.00    | 1.00      |
| Paralelo critical  | 2       |           |         |           |
| Paralelo critical  | 4       |           |         |           |
| Paralelo critical  | 8       |           |         |           |
| Paralelo atomic    | 2       |           |         |           |
| Paralelo atomic    | 4       |           |         |           |
| Paralelo atomic    | 8       |           |         |           |

### Log concorrente (hotspot)

| Vers√£o             | Threads | Tempo (s) | Speedup | Efici√™ncia |
|--------------------|---------|-----------|---------|-----------|
| Sequencial         | 1       |           | 1.00    | 1.00      |
| Paralelo critical  | 8       |           |         |           |
| Paralelo atomic    | 8       |           |         |           |

---

## üß† Principais aprendizados

- Diferen√ßa entre **desempenho te√≥rico** e **desempenho real** em paralelismo:
  - overhead de cria√ß√£o de threads
  - custo de sincroniza√ß√£o
  - impacto da hierarquia de mem√≥ria
- Efeito do **padr√£o de acesso aos dados**:
  - tr√°fego distribu√≠do tende a escalar melhor
  - hotspots geram conten√ß√£o intensa nas mesmas vari√°veis (URLs quentes)
- Compara√ß√£o pr√°tica entre `#pragma omp critical` e `#pragma omp atomic` em um cen√°rio realista de processamento de logs.
- Implementa√ß√£o de **tabela hash** em C e suas implica√ß√µes em ambiente paralelo.

---

## üöÄ Ideias de extens√µes

- Usar redu√ß√µes locais por thread e fazer merge dos resultados para diminuir conten√ß√£o.
- Adotar parti√ß√£o da tabela hash (por exemplo, uma hash por thread ou por conjunto de buckets).
- Gerar relat√≥rios autom√°ticos com Top N URLs mais acessadas (direto em C ou via Python).
- Adicionar m√©tricas extras: tempo de parsing, tempo de IO, tempo de atualiza√ß√£o de hash, etc.

